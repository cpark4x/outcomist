# v4.7 Question Type Detection System

**Date**: 2025-01-07
**Trigger**: Tests #13, #15, #16 revealed Outcomist mishandles information and execution requests
**Goal**: Detect question type BEFORE Tier 1 and route to appropriate flow

---

## The Problem

**Current behavior:** Outcomist treats ALL requests as decision questions requiring pattern recognition and discovery.

**What breaks:**
- **Test #13** (Similarity Question): "Is X similar to Y?" → Should research immediately, not ask clarifying questions
- **Test #15** (Children's Nutrition): "What meals should I make?" → Should provide practical how-to, not question the premise
- **Test #16** (Progesterone/Acne): "Why is this happening?" → Should research immediately, not ask "is this a decision or information request?"

**User feedback:**
- Test #15: "we wanted to explore different meal ideas and spent a lot of time to get here"
- Test #15: "feels a bit condescending like i am a bad parent" (questioning the goal)
- Test #16: "ChatGPT has better bedside manner. She would have gotten to the same outcome. Win for ChatGPT"

**The core issue:** Outcomist adds friction by asking meta-questions ("what type of help do you need?") when it should just deliver value immediately.

---

## The Solution: Question Type Detection (Step 0)

### New Flow Architecture

```
User provides statement via /explore
    ↓
┌─────────────────────────────────────┐
│ STEP 0: Question Type Detection    │
│ (NEW - happens before Tier 1)      │
└─────────────────────────────────────┘
    ↓
Classify into one of three types:
    ↓
┌─────────────┬──────────────┬─────────────┐
│ Information │  Execution   │  Decision   │
│   Request   │   Request    │   Question  │
└─────────────┴──────────────┴─────────────┘
    ↓               ↓              ↓
 Research      Practical      Pattern Recognition
 Immediately     How-To      + Discovery (current)
    ↓               ↓              ↓
 Deliver       Gather         Tier 2 Discovery
  Answer      Constraints         ↓
    ↓               ↓         Recommendation
Optional:     Deliver
"Need more?"  Output
```

---

## Question Type Patterns

### 1. Information Requests → Research Immediately

**Signals:**
- "Why is X happening?"
- "What causes Y?"
- "Can you explain Z?"
- "Is X similar to Y?"
- "What's the difference between...?"
- "How does [mechanism] work?"
- "What are the effects of...?"

**Flow:**
```
User: "Why is progesterone causing acne?"

Outcomist:
1. [Detect: Information request]
2. "Let me research that for you..."
3. [WebSearch immediately]
4. [Deliver comprehensive findings]
5. Optional: "Does this answer it, or is there a decision here?"
```

**Key principle:** No meta-questions, no gates, no friction. Get to value immediately.

**Examples from tests:**
- Test #13: "Is Outcomist similar to Decision Maker GPT?" → Research immediately
- Test #16: "Why is progesterone causing acne?" → Research immediately

---

### 2. Execution Requests → Practical How-To Immediately

**Signals:**
- "What meals should I make...?"
- "How do I implement...?"
- "What are some ideas for...?"
- "Can you help me create...?"
- "Give me suggestions for..."
- User has already received expert advice and wants to execute it
- User explicitly says they want to implement something

**Flow:**
```
User: "What meals should I make to maximize growth?"

Outcomist:
1. [Detect: Execution request]
2. "I'll help you create meals that maximize growth."
3. "Any dietary restrictions or preferences?"
4. [User provides constraints]
5. [Deliver practical meal list]
6. Optional: "Want help creating a weekly rotation?"
```

**Key principle:** Acknowledge the goal, gather practical constraints only, deliver output. Don't question the premise unless there's a safety concern.

**When to challenge the premise:**
- Clear safety concern (e.g., "meals to help my kid lose 50 lbs in a month")
- Obviously contradictory (e.g., "vegan meals with lots of meat")
- Requesting harmful advice

**Otherwise:** Assume user knows what they want, help them execute.

**Examples from tests:**
- Test #15: "What meals should I make to maximize growth?" → Gather dietary restrictions, deliver meal list

---

### 3. Decision Questions → Current Flow (Pattern Recognition + Discovery)

**Signals:**
- "Should I...?"
- "Which option...?"
- "Help me decide...?"
- "Is it worth...?"
- "What should I prioritize?"
- User explicitly asking for help with a decision
- Multiple options being weighed
- Uncertainty about direction

**Flow:**
```
User: "Should I take the client work or focus on my product?"

Outcomist:
1. [Detect: Decision question]
2. Tier 1 pattern recognition (current behavior)
3. Offer Tier 2 discovery
4. Deliver recommendation
```

**Key principle:** This is what Outcomist was built for. Use the current flow.

**Examples from tests:**
- Test #2: "I want to redesign my office" → Decision about what to prioritize (work vs personal)
- Test #7: "Client vs product decision" → Classic decision question

---

## Implementation Strategy

### Phase 1: Detection Logic

Add detection logic at the start of `/explore` command:

```python
def detect_question_type(user_statement: str) -> QuestionType:
    """
    Classify user statement into Information, Execution, or Decision.

    Returns:
        QuestionType.INFORMATION - research needed
        QuestionType.EXECUTION - practical how-to needed
        QuestionType.DECISION - discovery and recommendation needed
    """

    # Information request patterns
    info_patterns = [
        r"\bwhy\b.*\bhappening\b",
        r"\bwhat causes\b",
        r"\bcan you explain\b",
        r"\bis\b.*\bsimilar to\b",
        r"\bwhat\'?s the difference\b",
        r"\bhow does\b.*\bwork\b",
        r"\bwhat are the effects\b",
    ]

    # Execution request patterns
    exec_patterns = [
        r"\bwhat\b.*\bshould i make\b",
        r"\bhow do i implement\b",
        r"\bwhat are some ideas\b",
        r"\bcan you help me create\b",
        r"\bgive me suggestions\b",
        r"\bhelp me build\b",
    ]

    # Decision question patterns
    decision_patterns = [
        r"\bshould i\b",
        r"\bwhich option\b",
        r"\bhelp me decide\b",
        r"\bis it worth\b",
        r"\bwhat should i prioritize\b",
    ]

    # Check patterns in order
    if any(re.search(pattern, user_statement, re.IGNORECASE) for pattern in info_patterns):
        return QuestionType.INFORMATION

    if any(re.search(pattern, user_statement, re.IGNORECASE) for pattern in exec_patterns):
        return QuestionType.EXECUTION

    if any(re.search(pattern, user_statement, re.IGNORECASE) for pattern in decision_patterns):
        return QuestionType.DECISION

    # Default to decision (current behavior) if unclear
    return QuestionType.DECISION
```

### Phase 2: Routing Logic

```python
def handle_explore(user_statement: str):
    """Main /explore entry point with question type detection."""

    question_type = detect_question_type(user_statement)

    if question_type == QuestionType.INFORMATION:
        return handle_information_request(user_statement)

    elif question_type == QuestionType.EXECUTION:
        return handle_execution_request(user_statement)

    else:  # QuestionType.DECISION
        return handle_decision_question(user_statement)  # Current Tier 1 flow
```

### Phase 3: New Handlers

**Information Request Handler:**
```python
def handle_information_request(user_statement: str):
    """Handle information/research requests."""

    # Acknowledge and research immediately
    response = f"Let me research that for you...\n\n"

    # Perform WebSearch
    research_results = web_search(user_statement)

    # Deliver findings
    response += format_research_findings(research_results)

    # Optional follow-up
    response += "\n\nDoes this answer your question, or is there a decision you're facing here?"

    return response
```

**Execution Request Handler:**
```python
def handle_execution_request(user_statement: str):
    """Handle execution/how-to requests."""

    # Extract goal from statement
    goal = extract_goal(user_statement)

    # Acknowledge goal
    response = f"I'll help you {goal}.\n\n"

    # Gather constraints (minimal, focused)
    response += "Any constraints or preferences I should know about?\n"
    response += "- Dietary restrictions?\n"
    response += "- Time limitations?\n"
    response += "- Budget constraints?\n"
    response += "- Other considerations?\n\n"
    response += "Share what's relevant, and I'll provide practical recommendations."

    return response
```

---

## Success Criteria

### Test #13 succeeds in v4.7 if:
- ✅ "Is X similar to Y?" triggers immediate research
- ✅ No meta-questions about "is this a decision?"
- ✅ Comparison delivered within first exchange
- ✅ User doesn't feel friction

### Test #15 succeeds in v4.7 if:
- ✅ "What meals should I make?" triggers execution flow
- ✅ No pattern recognition questioning the goal
- ✅ Meal ideas delivered within 2 exchanges (constraint gathering + output)
- ✅ User doesn't feel condescended to

### Test #16 succeeds in v4.7 if:
- ✅ "Why is X happening?" triggers immediate research
- ✅ No asking "is this a decision or information request?"
- ✅ Research delivered within first exchange
- ✅ Bedside manner matches or beats ChatGPT

---

## Edge Cases

### Ambiguous Questions

Some questions could be multiple types:

**Example:** "What's the best way to handle X?"
- Could be information ("What approaches exist?")
- Could be execution ("How do I do this?")
- Could be decision ("Which approach should I choose?")

**Solution:** Default to DECISION type (current flow) when ambiguous. This is the safest default since it preserves the current behavior.

**Future improvement:** After delivering initial response, detect if user actually wanted a different type and pivot.

### Hybrid Requests

**Example:** "Why is X happening, and what should I do about it?"
- Information + Decision

**Solution:** Handle as DECISION type but include research phase. The decision flow can incorporate research (already does via v4.6 factual validation).

---

## Rollout Plan

### Phase 1: v4.7 Alpha (Internal Testing)
1. Implement detection logic
2. Implement information/execution handlers
3. Test with Tests #13, #15, #16
4. Verify improvements

### Phase 2: v4.7 Beta (Limited Release)
1. Run full regression suite (all 16 tests)
2. Collect user feedback
3. Refine detection patterns based on real usage
4. Document any new edge cases

### Phase 3: v4.7 Production
1. Update all documentation
2. Add detection patterns to pattern library
3. Update README with new capabilities
4. Announce improvements

---

## Open Questions

1. **Threshold for detection confidence**: How confident do we need to be before routing to non-decision flow?
   - **Proposed**: Medium confidence required. When low, default to decision (current behavior).

2. **User override**: If detection gets it wrong, how does user correct?
   - **Proposed**: If user provides feedback suggesting wrong type, pivot to correct flow.

3. **Hybrid questions**: How to handle questions that span multiple types?
   - **Proposed**: Default to decision type, which can incorporate research/execution as needed.

---

## Comparison to v4.6

**v4.6 behavior:**
- ALL requests → Tier 1 pattern recognition
- Information requests → Meta-questions about what type of help
- Execution requests → Pattern recognition questions the premise

**v4.7 behavior:**
- Step 0: Detect question type first
- Information requests → Research immediately
- Execution requests → Practical how-to immediately
- Decision requests → Current flow (Tier 1 → 2 → 3)

**Expected improvement:**
- Faster time-to-value for information/execution requests
- Better "bedside manner" (less friction)
- Matches or beats ChatGPT UX for non-decision questions
- Decision questions still get full discovery (the core value prop)

---

## Implementation Notes

**Priority**: HIGH - This fixes 3 documented test failures (Tests #13, #15, #16)

**Complexity**: MEDIUM - New logic before Tier 1, but doesn't change Tier 1-4 architecture

**Risk**: LOW - Default to decision type when ambiguous (preserves current behavior)

**Timeline**: 1-2 days for implementation + testing

---

**Next Steps:**
1. Update `.claude/commands/explore.md` with Step 0 detection
2. Implement information/execution handlers
3. Rerun Tests #13, #15, #16 with v4.7
4. Document results
5. Run full regression suite

---

**Date Created**: 2025-01-07
**Status**: Design complete, ready for implementation
**Impact**: Fixes 3 test failures, improves UX for non-decision questions
